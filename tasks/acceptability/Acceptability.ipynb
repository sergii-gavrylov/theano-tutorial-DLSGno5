{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return theano.tensor.nnet.sigmoid(x)\n",
    "\n",
    "\n",
    "def rectify(x):\n",
    "    return T.maximum(0.0, x)\n",
    "\n",
    "\n",
    "def get_by_name(name):\n",
    "    if name == 'sigmoid':\n",
    "        return sigmoid\n",
    "    elif name == 'rectify':\n",
    "        return rectify\n",
    "    else:\n",
    "        raise ValueError('There is no such name:{}'.format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import random\n",
    "\n",
    "\n",
    "rng = random.RandomState(seed=42)\n",
    "\n",
    "\n",
    "def get_constant(shape, val=0.0):\n",
    "    c = np.empty(shape)\n",
    "    c.fill(val)\n",
    "    return c\n",
    "\n",
    "\n",
    "def get_uniform(shape, init_range):\n",
    "    init_range = (-init_range, init_range)\n",
    "    return rng.uniform(low=init_range[0], high=init_range[1], size=shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Layer(object):\n",
    "    def __init__(self, W_init, b_init, activation_fun, name):\n",
    "        self.name = name\n",
    "        self.W = theano.shared(value=W_init, name=name+'_W', borrow=True)\n",
    "        self.b = theano.shared(value=b_init, name=name+'_b', borrow=True)\n",
    "        self.activation_fun = activation_fun\n",
    "\n",
    "    def get_forward_pass_expr(self, matrix):\n",
    "        pre_activation = T.dot(matrix, self.W) + self.b\n",
    "        return self.activation_fun(pre_activation)\n",
    "\n",
    "    def get_parameters(self):\n",
    "        return [self.W, self.b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle\n",
    "from itertools import izip_longest\n",
    "\n",
    "\n",
    "class NeuralNetwork(object):\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "        self.predict_expr = None\n",
    "        self.cross_entropy_expr = None\n",
    "        self.batch_matrix = T.matrix('batch_matrix')\n",
    "        self.true_labels = T.matrix('true_labels')\n",
    "        self.__cross_entropy = None\n",
    "        self.__predict = None\n",
    "\n",
    "    def add_layer(self, layer):\n",
    "        self.layers.append(layer)\n",
    "\n",
    "    def get_parameters(self):\n",
    "        return sum([layer.get_parameters() for layer in self.layers], [])\n",
    "\n",
    "    def finalize(self):\n",
    "        self.predict_expr = self.batch_matrix\n",
    "        for layer in self.layers:\n",
    "            self.predict_expr = layer.get_forward_pass_expr(self.predict_expr)\n",
    "        self.cross_entropy_expr = \\\n",
    "            -T.mean(T.log(self.true_labels * self.predict_expr +\n",
    "                          (1.0 - self.true_labels) * (1.0 - self.predict_expr) + 1e-5))\n",
    "        self.__cross_entropy = \\\n",
    "            theano.function(inputs=[self.batch_matrix, self.true_labels],\n",
    "                            outputs=self.cross_entropy_expr)\n",
    "        self.__predict = theano.function(inputs=[self.batch_matrix],\n",
    "                                         outputs=self.predict_expr)\n",
    "\n",
    "    def get_cross_entropy_loss(self, batch_matrix, true_labels):\n",
    "        return self.__cross_entropy(batch_matrix, true_labels)\n",
    "\n",
    "    def predict(self, features):\n",
    "        return self.__predict(features)\n",
    "\n",
    "    def save(self, file_path):\n",
    "        params = []\n",
    "        for layer in self.layers:\n",
    "            params.append(layer.name)\n",
    "            params.append(layer.activation_fun.__name__)\n",
    "            params.append(layer.W.get_value())\n",
    "            params.append(layer.b.get_value())\n",
    "        with open(file_path, 'wb') as f:\n",
    "            cPickle.dump(params, f)\n",
    "\n",
    "    @staticmethod\n",
    "    def load(model_path):\n",
    "        grouper = lambda iterable: izip_longest(*([iter(iterable)] * 4))\n",
    "\n",
    "        with open(model_path) as f:\n",
    "            params = cPickle.load(f)\n",
    "\n",
    "        nn = NeuralNetwork()\n",
    "        for layer_name, act_fun_name, W, b in grouper(params):\n",
    "            act_fun = get_by_name(act_fun_name)\n",
    "            l = Layer(W, b, act_fun, layer_name)\n",
    "            nn.add_layer(l)\n",
    "        nn.finalize()\n",
    "        return nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_momentum_updates(loss_expr, parameters):\n",
    "    grads = T.grad(cost=loss_expr, wrt=parameters)\n",
    "    updates = []\n",
    "    for param, grad in zip(parameters, grads):\n",
    "        velocity = theano.shared(np.zeros_like(param.get_value()))\n",
    "        v = 0.95 * velocity - 0.1 * grad\n",
    "        p = param + v\n",
    "        updates.append((velocity, v))\n",
    "        updates.append((param, p))\n",
    "    return updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nn = NeuralNetwork()\n",
    "\n",
    "W_init = get_uniform(shape=(600, 300), init_range=0.1)\n",
    "b_init = get_uniform(shape=300, init_range=0.05)\n",
    "l = Layer(W_init, b_init, rectify, 'layer_1_rectify')\n",
    "nn.add_layer(l)\n",
    "\n",
    "W_init = get_uniform(shape=(300, 100), init_range=0.1)\n",
    "b_init = get_uniform(shape=100, init_range=0.05)\n",
    "l = Layer(W_init, b_init, rectify, 'layer_2_rectify')\n",
    "nn.add_layer(l)\n",
    "\n",
    "W_init = get_constant(shape=(100, 1))\n",
    "b_init = get_constant(shape=1)\n",
    "l = Layer(W_init, b_init, sigmoid, 'layer_3_sigmoid')\n",
    "nn.add_layer(l)\n",
    "\n",
    "nn.finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from itertools import count\n",
    "from utils.DataIterator import DataIterator\n",
    "\n",
    "train_data_iterator = DataIterator(\"data/t.txt\", batch_size=128)\n",
    "validation_data_iterator = DataIterator(\"data/v.txt\", batch_size=500)\n",
    "print('train_dataset_size: {}'.format(len(train_data_iterator.adjective_noun_phrases)))\n",
    "print('valid_dataset_size: {}'.format(len(validation_data_iterator.adjective_noun_phrases)))\n",
    "train_data_iterator = train_data_iterator.get_infinite_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from itertools import count\n",
    "\n",
    "momentum_updates = get_momentum_updates(loss_expr=nn.cross_entropy_expr,\n",
    "                                        parameters=nn.get_parameters())\n",
    "\n",
    "update_nn_params = theano.function(inputs=[nn.batch_matrix, nn.true_labels],\n",
    "                                   outputs=nn.cross_entropy_expr,\n",
    "                                   updates=momentum_updates)\n",
    "\n",
    "save_freq = 1000\n",
    "valid_freq = 500\n",
    "max_iters = 5000\n",
    "train_cross_entropy = []\n",
    "for iter_num in count():\n",
    "    if iter_num % valid_freq == 0:\n",
    "        print('iter_num: {}'.format(iter_num))\n",
    "        losses = []\n",
    "        for batch_matrix, true_labels in validation_data_iterator.get_iterator():\n",
    "            loss = nn.get_cross_entropy_loss(batch_matrix, true_labels)\n",
    "            losses.append(loss)\n",
    "        print('valid_loss: {:1.10f}'.format(np.mean(losses)))\n",
    "\n",
    "    batch_matrix, true_labels = train_data_iterator.next()\n",
    "    loss = update_nn_params(batch_matrix, true_labels)\n",
    "    train_cross_entropy.append(loss)\n",
    "\n",
    "    if iter_num % save_freq == 0 and iter_num != 0:\n",
    "        print('iter_num: {}'.format(iter_num))\n",
    "        print('saving model...')\n",
    "        nn.save('data/models/{}.mdl'.format(iter_num))\n",
    "        print('saved')\n",
    "\n",
    "    if iter_num >= max_iters:\n",
    "        print('iter_num: {}'.format(iter_num))\n",
    "        print('max iters limit!!!')\n",
    "        print('saving model...')\n",
    "        nn.save('data/models/{}.mdl'.format(iter_num))\n",
    "        print('saved')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn = NeuralNetwork.load('data/models/5000.mdl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def p(adj, noun):\n",
    "    features = DataIterator.get_features(adj, noun)\n",
    "    print '%20s %-20s %0.5f' % (adj, noun, nn.predict(features)[0][0])\n",
    "\n",
    "p('colourless', 'ideas')\n",
    "p('interesting', 'ideas')\n",
    "p('monthly', 'democracy')\n",
    "p('reproducible', 'experiment')\n",
    "p('fragrant', 'stench')\n",
    "p('direct', 'democracy')\n",
    "p('reproducible', 'accelerator')\n",
    "p('unbiased', 'neighborhood')\n",
    "p('unbiased', 'opinion')\n",
    "p('noisy', 'semiconductor')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
